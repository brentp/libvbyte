x die tabelle statisch vorberechnen
x benchmark-framework aufsetzen, zeiten messen (bzw. den test ausbauen)
x maske mit SSE berechnen
x weiteren ablauf mit SSE beschleunigen

-> 1. plain old implementation
   2. scalar implementation, maske/tabelle berechnen
   3. scalar implementation, lookup-tabelle (groß)
   4. das schnellste von 2/3 mit SSE-maske
   5. masked vbyte
   6. Alles SSE wenn möglich

==================================================

bislang keine verbesserung...
wäre es nicht besser nur die "plain"-funktion zu unterstützen, aber
mit templates (für uint32_t und uint64_t)?
dank der mask könnte man leicht eine lookup-table bauen um ein richtig
schnelles select/find zu implementieren. das wäre doch ausreichend -
encode/decode ist offenbar schnell genug und nicht zu optimieren...

die lookup-table benötigt dann nur 2 byte per line: (128 kb)
    - num_bytes (für schnelles find)
    - num_ints (für schnelles select)

dann funktionen für
- insert
- append
- erase
- merge
- find
- select

dann noch alles mit delta-encoding!?
==================================================

mit pshufb in 4 _m128i-register à 4 integer aufsplitten:
if (length > 0) {
  m128i mask = _mm_set_epi8 (char b15, char b14,...);
  pushfb(in, out[0], mask);
  in += x;
}
if (length > 4) {
  m128i mask = _mm_set_epi8 (char b15, char b14,...);
  pushfb(in, out[4], mask);
  in += x;
}
...
http://stackoverflow.com/questions/16584520/sse2-instruction-to-load-integers-in-reverse-order

dann alle bits "rausshiften"
https://software.intel.com/en-us/forums/intel-isa-extensions/topic/285022

- delta-encoding
- schnelle lookup-funktion
- schnelle select-funktion
- schöne library draus machen


== NOTES ==

working on integers is more efficient than working with byte arrays:

          uint32_t v = *(uint32_t *)&in[0];
          *out =   ((v & 0x7F00u) >> 1)
                 |  (v & 0x7Fu);

    old:
          *out =   ((in[1] & 0x7Fu) << 7)
                  | (in[0] & 0x7Fu);
